{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfbc1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Requirement already satisfied: numpy in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "105e3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to process frame\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def change_perspective(image, fov, pitch=0, yaw=0):\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Define intrinsic camera matrix\n",
    "    focal_length = width / (2 * np.tan(fov / 2))\n",
    "    K = np.array([[focal_length, 0, width / 2],\n",
    "                  [0, focal_length, height / 2],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    # Define rotation matrix\n",
    "    pitch = np.deg2rad(pitch)\n",
    "    yaw = np.deg2rad(yaw)\n",
    "    R_pitch = np.array([[1, 0, 0],\n",
    "                        [0, np.cos(pitch), -np.sin(pitch)],\n",
    "                        [0, np.sin(pitch), np.cos(pitch)]])\n",
    "    R_yaw = np.array([[np.cos(yaw), 0, np.sin(yaw)],\n",
    "                      [0, 1, 0],\n",
    "                      [-np.sin(yaw), 0, np.cos(yaw)]])\n",
    "    R = np.dot(R_yaw, R_pitch)\n",
    "\n",
    "    map_x, map_y = cv2.initUndistortRectifyMap(K, None, R, K, (width, height), cv2.CV_32FC1)\n",
    "    perspective_view = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return perspective_view\n",
    "\n",
    "# def get_transformation_matrix([yaw, pitch, roll], position):\n",
    "#     return ([\n",
    "#         [math.cos(yaw) * math.cos(pitch), -math.sin(yaw), math.cos(yaw) * math.sin(pitch), position[0]],\n",
    "#         [math.sin(yaw) * math.cos(pitch), math.cos(yaw), math.sin(yaw) * math.sin(pitch), position[1]],\n",
    "#         [-math.sin(pitch), 0, math.cos(pitch) , position[2]],\n",
    "#         [0, 0, 0, 1]\n",
    "#     ])\n",
    "\n",
    "\n",
    "def generate_transform_matrix(rot, pos):\n",
    "    def Rx(theta):\n",
    "      return np.matrix([[ 1, 0            , 0            ],\n",
    "                        [ 0, np.cos(theta),-np.sin(theta)],\n",
    "                        [ 0, np.sin(theta), np.cos(theta)]])\n",
    "    def Ry(theta):\n",
    "      return np.matrix([[ np.cos(theta), 0, np.sin(theta)],\n",
    "                        [ 0            , 1, 0            ],\n",
    "                        [-np.sin(theta), 0, np.cos(theta)]])\n",
    "    def Rz(theta):\n",
    "      return np.matrix([[ np.cos(theta), -np.sin(theta), 0 ],\n",
    "                        [ np.sin(theta), np.cos(theta) , 0 ],\n",
    "                        [ 0            , 0             , 1 ]])\n",
    "\n",
    "    R = Rz(rot[2]) * Ry(rot[1]) * Rx(rot[0])\n",
    "    xf_rot = np.eye(4)\n",
    "    xf_rot[:3,:3] = R\n",
    "\n",
    "    xf_pos = np.eye(4)\n",
    "    xf_pos[:3,3] = pos\n",
    "\n",
    "    # barbershop_mirros_hd_dense:\n",
    "    # - camera plane is y+z plane, meaning: constant x-values\n",
    "    # - cameras look to +x\n",
    "\n",
    "    # Don't ask me...\n",
    "    extra_xf = np.matrix([\n",
    "        [-1, 0, 0, 0],\n",
    "        [ 0, 0, 1, 0],\n",
    "        [ 0, 1, 0, 0],\n",
    "        [ 0, 0, 0, 1]])\n",
    "    # NerF will cycle forward, so lets cycle backward.\n",
    "    shift_coords = np.matrix([\n",
    "        [0, 0, 1, 0],\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 0, 1]])\n",
    "    xf = shift_coords @ extra_xf @ xf_pos\n",
    "    assert np.abs(np.linalg.det(xf) - 1.0) < 1e-4\n",
    "    xf = xf @ xf_rot\n",
    "    return xf\n",
    "    \n",
    "\n",
    "def process_frame(frame, position):\n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # Split image\n",
    "    top_half = frame[:height // 2, :]\n",
    "    bottom_half = frame[height // 2:, :]\n",
    "    \n",
    "    width_splits = [[0, width // 3], [(width // 3), 2*(width // 3)], [2*(width // 3), width]]\n",
    "    print(width_splits)\n",
    "    \n",
    "    # Process top half\n",
    "    images = [top_half[:, width_split[0]:width_split[1]] for width_split in width_splits]\n",
    "    \n",
    "    # Process bottom half\n",
    "    images = images + [\n",
    "        # cv2.rotate(bottom_half[:, width_splits[0][0]:width_splits[0][1]], cv2.ROTATE_90_CLOCKWISE), \n",
    "        # cv2.rotate(bottom_half[:, width_splits[1][0]:width_splits[1][1]], cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        # cv2.rotate(bottom_half[:, width_splits[2][0]:width_splits[2][1]], cv2.ROTATE_90_CLOCKWISE),\n",
    "        bottom_half[:, width_splits[0][0]:width_splits[0][1]],\n",
    "        bottom_half[:, width_splits[1][0]:width_splits[1][1]],\n",
    "        bottom_half[:, width_splits[2][0]:width_splits[2][1]]\n",
    "    ]\n",
    "    \n",
    "    images = [change_perspective(image, np.pi/2) for image in images]\n",
    "    \n",
    "    # Add transformation matrix to each image, images in order of left to right (top row first)   \n",
    "    return ([\n",
    "        (images[0], generate_transform_matrix([0, np.pi/2, 0], position)),\n",
    "        (images[1], generate_transform_matrix([0, 0, 0], position)),\n",
    "        (images[2], generate_transform_matrix([0, -np.pi/2, 0], position)),\n",
    "        (images[3], generate_transform_matrix([-np.pi/2, -np.pi/2, 0], position)),\n",
    "        (images[4], generate_transform_matrix([0, np.pi, -np.pi/2], position))\n",
    "        # (images[5], generate_transform_matrix([0, -np.pi/2, 0], position)),\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e6ff27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "397\n",
      "[[0, 640], [640, 1280], [1280, 1920]]\n",
      "[[0, 640], [640, 1280], [1280, 1920]]\n",
      "[[0, 640], [640, 1280], [1280, 1920]]\n",
      "[[0, 640], [640, 1280], [1280, 1920]]\n",
      "[[0, 640], [640, 1280], [1280, 1920]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "# Velocity is a hyperparameter that should be set (in m/s)\n",
    "velocity = 0.8\n",
    "\n",
    "video_path = '360_video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(frame_rate)\n",
    "print(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Set transformation json\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, frame = cap.read()\n",
    "height, width = frame.shape[:2]\n",
    "height = height / 2\n",
    "width = width / 3\n",
    "\n",
    "transformations = {\n",
    "    \"camera_angle_x\": np.pi / 2,\n",
    "    \"camera_angle_y\": np.pi / 2,\n",
    "    \"fl_x\": width / (2 * np.tan(np.pi / 4)),\n",
    "    \"fl_y\": height / (2 * np.tan(np.pi / 4)),\n",
    "    \"k1\": 0,\n",
    "    \"k2\": 0,\n",
    "    \"p1\": 0,\n",
    "    \"p2\": 0,\n",
    "    \"cx\": width / 2,\n",
    "    \"cy\": height / 2,\n",
    "    \"w\": width,\n",
    "    \"h\": height,\n",
    "    \"aabb_scale\": 4\n",
    "}\n",
    "frame_transformations = []\n",
    "\n",
    "# Process each frame and save to file\n",
    "for time_step in range(0, 5): #frame_count // int(frame_rate)):\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, time_step)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Get position using velocity and time step\n",
    "    position = [0, 0, (velocity * time_step)]\n",
    "    \n",
    "    perspective_imgs = process_frame(frame, position)\n",
    "    # Sace each image\n",
    "    for image_idx, image_tuple in enumerate(perspective_imgs):\n",
    "        cv2.imwrite(f'./images/{str(time_step*6 + image_idx).zfill(5)}.jpg', image_tuple[0])\n",
    "        \n",
    "        frame_transformations.append({\n",
    "            \"file_path\": f'images/{str(time_step*6 + image_idx).zfill(5)}.jpg',\n",
    "            \"sharpness\": 25,\n",
    "            \"transform_matrix\": image_tuple[1].tolist()\n",
    "        })\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Save transformations\n",
    "transformations[\"frames\"] = frame_transformations\n",
    "with open('transforms.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(transformations, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e1db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
